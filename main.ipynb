{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_MNIST, load_and_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 loss: 84.40394531885782 acc: 0.09751666666666652 sub_acc: 0.0\n",
      "Testdata loss: 72.98033123016357 acc: 0.09740000000000006 sub acc: 0.0\n",
      "Reproduced results: 72.98033123016357 0.09740000000000006 0.0\n",
      "Epoch: 0 loss: 122.20373544692993 acc: 0.09923333333333322 sub_acc: 0.09914999999999992\n",
      "Testdata loss: 116.13876972198486 acc: 0.10280000000000007 sub acc: 0.10090000000000003\n",
      "Hierarchical results: 116.13876972198486 0.10280000000000007 0.10090000000000003\n"
     ]
    }
   ],
   "source": [
    "# Trains an entire model and saves it to ./from_jupyter/models/final.pt(h)\n",
    "# None of the parameters are required\n",
    "# This code runs our two models with default parameters as described in the paper:\n",
    "# Learning rate 0.0001, epochs = 1500\n",
    "# Nonhierarchical with n_prototypes = 15 (reproduced results)\n",
    "# Hierarchical with n_prototypes = 10 and n_sub_prototypes = 20 \n",
    "\n",
    "seed = 42\n",
    "lambda_dict = {'lambda_class' : 20, \n",
    "                    'lambda_class_sup' : 20,\n",
    "                    'lambda_class_sub' : 20,\n",
    "                    'lambda_ae' : 1,\n",
    "                    'lambda_r1' : 1,\n",
    "                    'lambda_r2' : 1,\n",
    "                    'lambda_r3' : 1,\n",
    "                    'lambda_r4' : 1}\n",
    "\n",
    "test_loss, test_acc, test_subacc = train_MNIST(training_epochs=1, hierarchical = False, seed = seed, directory='from_jupyter', lambda_dict = lambda_dict)\n",
    "\n",
    "print(\"Reproduced results:\", test_loss, test_acc, test_subacc)\n",
    "\n",
    "\n",
    "test_lossH, test_accH, test_subaccH = train_MNIST(training_epochs=1, hierarchical=True)\n",
    "\n",
    "\n",
    "print(\"Hierarchical results:\", test_lossH, test_accH, test_subaccH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading an existing model and running it on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_and_test('normal1/models/final.pth', False )\n",
    "#load_and_test('hierarchical1/models/final.pth', True)\n",
    "import torch\n",
    "model = torch.load('normal1/models/final.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8928,  1.0061, -1.2566,  0.7862,  0.9423,  1.3012, -0.5188,  0.9896,\n",
       "         -0.0601, -0.6135],\n",
       "        [-0.4296,  1.3325, -0.2708,  0.7536,  0.9070,  0.8309,  0.4379,  0.6905,\n",
       "         -6.0999,  0.1868],\n",
       "        [ 0.1116, -4.8329, -0.3858,  0.1931, -0.1114,  0.3443,  0.3533,  0.2985,\n",
       "         -0.0245,  1.0401],\n",
       "        [-0.2977,  0.4170,  0.4650, -0.3020, -0.3693, -0.5929, -6.0174,  0.8985,\n",
       "         -0.0223,  0.9917],\n",
       "        [ 0.7107,  0.4082,  0.4278,  0.1653, -0.7899,  1.0900,  1.4659, -0.3194,\n",
       "          0.4034, -5.5150],\n",
       "        [ 0.4233, -0.1067,  0.2541,  0.8536, -4.3679, -0.0280,  0.4313, -0.4669,\n",
       "          1.0273, -0.8905],\n",
       "        [ 0.8823,  0.6089, -0.4829, -4.1300,  1.0304, -0.5967,  0.3173,  0.3490,\n",
       "          0.0586,  0.6024],\n",
       "        [ 0.5597,  1.0659,  0.7905,  1.0503, -3.2500,  0.4728, -0.7443,  0.4380,\n",
       "         -1.1582, -0.3791],\n",
       "        [ 0.3483, -0.3950,  0.7470, -0.0861,  0.5273,  0.1080,  1.4262, -5.6675,\n",
       "          0.7239,  0.0454],\n",
       "        [ 0.8723,  0.4875,  0.9568, -3.4913,  0.7637, -0.9731,  1.0142,  0.4290,\n",
       "          0.2080, -1.6301],\n",
       "        [-3.3583,  0.6130,  0.3933,  0.9909,  0.7282, -0.9529, -0.6800, -0.3445,\n",
       "          1.0284, -0.0439],\n",
       "        [ 0.4961,  0.3321,  0.9017, -0.2864,  0.6807, -5.0458, -0.6680,  0.5897,\n",
       "          0.4184,  0.3993],\n",
       "        [-0.5532, -0.0142, -4.9834, -0.8538,  0.0166,  1.6081,  0.0828,  0.5165,\n",
       "          0.1307,  1.2064],\n",
       "        [ 0.7184, -2.0828, -0.1306,  0.9237, -0.7575, -0.2242, -0.1542, -2.0461,\n",
       "          0.4659,  1.7817],\n",
       "        [ 0.4222, -4.7165,  0.3184, -0.2698,  0.6270,  0.2404,  0.0843,  0.9303,\n",
       "          0.4925, -0.4178]], grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prototype.linear1.weight.t()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
